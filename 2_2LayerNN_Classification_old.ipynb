{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWOc48yQrvUI"
      },
      "source": [
        "# Implement simple NN model for classification\n",
        "\n",
        "For this notebook, we will just use MNIST for basic analysis. The purpose is to play with a simple network in pytorch for image classification and tinker with batch norm.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mLNTKY8sEUj",
        "outputId": "d25988bb-ce33-45ac-9b0c-991e75a6743f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(device(type='cpu'), 4)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# imports\n",
        "import os\n",
        "import csv\n",
        "import json\n",
        "import random\n",
        "import pathlib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dev, torch.get_num_threads()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Get MNIST data\n",
        "Load directly from torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "9913344it [00:01, 6619801.94it/s]                             \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "29696it [00:00, 12877796.90it/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "1649664it [00:00, 8488192.20it/s]                            \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5120it [00:00, 10802231.63it/s]         \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define transorms to apply to data\n",
        "transform = [transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))]\n",
        "batch_size_train, batch_size_test = 64, 1000\n",
        "\n",
        "# Get training data\n",
        "train_loader = torch.utils.data.DataLoader(datasets.MNIST('../data/', train=True, download=True,\n",
        "                transform=transforms.Compose(transform)),batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "# Get test data\n",
        "test_loader = torch.utils.data.DataLoader(datasets.MNIST('../data/', train=False, download=True,\n",
        "                             transform=transforms.Compose(transform)),batch_size=batch_size_test, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's define a simple network with just a activation(layer) for layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up simple network with user defined activation function and numbber of layer units\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, actv, num_inputs, hidden_units, num_outputs):\n",
        "        super(Net, self).__init__()\n",
        "        # Get activation function\n",
        "        exec('self.actv = nn.%s'%actv)   \n",
        "        # Define layers\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i in range(len(hidden_units)):\n",
        "          next_num_inputs = hidden_units[i] \n",
        "          self.layers += [nn.Linear(num_inputs, next_num_inputs)]\n",
        "          num_inputs = next_num_inputs\n",
        "\n",
        "        self.out = nn.Linear(num_inputs, num_outputs)\n",
        "        \n",
        "    # Make the forward pass\n",
        "    def forward(self, x):\n",
        "        # Flattening\n",
        "        x = x.view(x.shape[0], -1)  \n",
        "        \n",
        "        # Apply activation function to each layer on the input \n",
        "        for layer in self.layers:\n",
        "          x = self.actv(layer(x))\n",
        "        x = self.out(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's define a main() function for doing the train/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def progress(epoch, loss, epochs=100):\n",
        "    return HTML(\"\"\"\n",
        "        <label for=\"file\">Training loss: {loss}</label>\n",
        "        <progress\n",
        "            value='{epoch}'\n",
        "            max='{epochs}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {epoch}\n",
        "        </progress>\n",
        "    \"\"\".format(loss=loss, epoch=epoch, epochs=epochs))\n",
        "\n",
        "\n",
        "# Define training function\n",
        "def test(data_loader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for (inputs, labels) in data_loader:\n",
        "      # inputs = inputs.to(dev).float()\n",
        "      # labels = labels.to(dev).long()\n",
        "\n",
        "      outputs = net(inputs)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  acc = 100 * correct / total\n",
        "  return total, acc\n",
        "\n",
        "\n",
        "def main(net, criterion, optimizer,train_loader,num_epochs=1, verbose=True, training_plot=True):\n",
        "  if verbose:\n",
        "    progress_bar = display(progress(0, 0, num_epochs), display_id=True)\n",
        "\n",
        "  # Set to train = true\n",
        "  net.train()\n",
        "  training_losses = []\n",
        "\n",
        "  for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "      running_loss = 0.0\n",
        "      for i, (inputs,labels) in enumerate(train_loader, 0):\n",
        "          # # get the inputs; data is a list of [inputs, labels]\n",
        "          # inputs, labels = data\n",
        "          # inputs = inputs.to(dev).float()\n",
        "          # labels = labels.to(dev).long()\n",
        "\n",
        "          # zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Make forward pass\n",
        "          outputs = net(inputs)\n",
        "\n",
        "          # Compute Loss\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          # Make backward pass and step optimizer\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # Print statistics\n",
        "          if verbose:\n",
        "            training_losses += [loss.item()]\n",
        "            running_loss += loss.item()\n",
        "            if i % 10 == 9:    # update every 10 mini-batches\n",
        "                progress_bar.update(progress(epoch+1, running_loss / 10, num_epochs))\n",
        "                running_loss = 0.0\n",
        "  \n",
        "  # Evaluate net\n",
        "  net.eval()\n",
        "\n",
        "  train_total, train_acc = test(train_loader)\n",
        "\n",
        "  if verbose:\n",
        "    print('Accuracy on the %d training samples: %0.2f %%' % (train_total, train_acc))\n",
        "\n",
        "  if training_plot:\n",
        "    plt.plot(training_losses)\n",
        "    plt.xlabel('Batch')\n",
        "    plt.ylabel('Training loss')\n",
        "    plt.show()\n",
        "  \n",
        "  return train_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 1, 28, 28])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "examples = enumerate(train_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "example_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "        <label for=\"file\">Training loss: 0.09552026093006134</label>\n",
              "        <progress\n",
              "            value='16'\n",
              "            max='500',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            16\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/justinbrantley/Dropbox/KLAB/Deep-Learning/2_2LayerNN_Classification_old.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/justinbrantley/Dropbox/KLAB/Deep-Learning/2_2LayerNN_Classification_old.ipynb#ch0000045?line=3'>4</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()  \u001b[39m#nn.MultiMarginLoss(margin=1.0) \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/justinbrantley/Dropbox/KLAB/Deep-Learning/2_2LayerNN_Classification_old.ipynb#ch0000045?line=4'>5</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mSGD(net\u001b[39m.\u001b[39mparameters(),lr\u001b[39m=\u001b[39m\u001b[39m1e-2\u001b[39m)\u001b[39m#,momentum=0.5)# optim.Adam(net.parameters(), lr=1e-4)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/justinbrantley/Dropbox/KLAB/Deep-Learning/2_2LayerNN_Classification_old.ipynb#ch0000045?line=5'>6</a>\u001b[0m train_acc \u001b[39m=\u001b[39m main(net, criterion, optimizer,train_loader,num_epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m)\n",
            "\u001b[1;32m/Users/justinbrantley/Dropbox/KLAB/Deep-Learning/2_2LayerNN_Classification_old.ipynb Cell 8'\u001b[0m in \u001b[0;36mmain\u001b[0;34m(net, criterion, optimizer, train_loader, num_epochs, verbose, training_plot)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/justinbrantley/Dropbox/KLAB/Deep-Learning/2_2LayerNN_Classification_old.ipynb#ch0000039?line=38'>39</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):  \u001b[39m# loop over the dataset multiple times\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/justinbrantley/Dropbox/KLAB/Deep-Learning/2_2LayerNN_Classification_old.ipynb#ch0000039?line=39'>40</a>\u001b[0m     running_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/justinbrantley/Dropbox/KLAB/Deep-Learning/2_2LayerNN_Classification_old.ipynb#ch0000039?line=40'>41</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, (inputs,labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader, \u001b[39m0\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/justinbrantley/Dropbox/KLAB/Deep-Learning/2_2LayerNN_Classification_old.ipynb#ch0000039?line=41'>42</a>\u001b[0m         \u001b[39m# # get the inputs; data is a list of [inputs, labels]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/justinbrantley/Dropbox/KLAB/Deep-Learning/2_2LayerNN_Classification_old.ipynb#ch0000039?line=42'>43</a>\u001b[0m         \u001b[39m# inputs, labels = data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/justinbrantley/Dropbox/KLAB/Deep-Learning/2_2LayerNN_Classification_old.ipynb#ch0000039?line=43'>44</a>\u001b[0m         \u001b[39m# inputs = inputs.to(dev).float()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/justinbrantley/Dropbox/KLAB/Deep-Learning/2_2LayerNN_Classification_old.ipynb#ch0000039?line=44'>45</a>\u001b[0m         \u001b[39m# labels = labels.to(dev).long()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/justinbrantley/Dropbox/KLAB/Deep-Learning/2_2LayerNN_Classification_old.ipynb#ch0000039?line=45'>46</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/justinbrantley/Dropbox/KLAB/Deep-Learning/2_2LayerNN_Classification_old.ipynb#ch0000039?line=46'>47</a>\u001b[0m         \u001b[39m# zero the parameter gradients\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/justinbrantley/Dropbox/KLAB/Deep-Learning/2_2LayerNN_Classification_old.ipynb#ch0000039?line=47'>48</a>\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/justinbrantley/Dropbox/KLAB/Deep-Learning/2_2LayerNN_Classification_old.ipynb#ch0000039?line=49'>50</a>\u001b[0m         \u001b[39m# Make forward pass\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=568'>569</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=569'>570</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=570'>571</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=571'>572</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
            "File \u001b[0;32m~/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/datasets/mnist.py?line=141'>142</a>\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/datasets/mnist.py?line=143'>144</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/datasets/mnist.py?line=144'>145</a>\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/datasets/mnist.py?line=146'>147</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/datasets/mnist.py?line=147'>148</a>\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
            "File \u001b[0;32m~/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=92'>93</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=93'>94</a>\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=94'>95</a>\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=95'>96</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
            "File \u001b[0;32m~/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/transforms/transforms.py:135\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=126'>127</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=127'>128</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=128'>129</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=129'>130</a>\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=132'>133</a>\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=133'>134</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=134'>135</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
            "File \u001b[0;32m~/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/transforms/functional.py:155\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=152'>153</a>\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mpermute((\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mcontiguous()\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=153'>154</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mByteTensor):\n\u001b[0;32m--> <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=154'>155</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39;49mto(dtype\u001b[39m=\u001b[39;49mdefault_float_dtype)\u001b[39m.\u001b[39;49mdiv(\u001b[39m255\u001b[39;49m)\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=155'>156</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/justinbrantley/miniconda3/envs/pytorch_local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=156'>157</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "hidden_layers = [32]\n",
        "# net = BNDeepNet().to(dev) \n",
        "net = Net('ReLU()', 1*28*28, hidden_layers, 10).to(dev) \n",
        "criterion = nn.CrossEntropyLoss()  #nn.MultiMarginLoss(margin=1.0) \n",
        "optimizer = optim.SGD(net.parameters(),lr=1e-2)#,momentum=0.5)# optim.Adam(net.parameters(), lr=1e-4)\n",
        "train_acc = main(net, criterion, optimizer,train_loader,num_epochs=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFpjwPq78MdR"
      },
      "outputs": [],
      "source": [
        "# # @title Helper functions\n",
        "# def imshow(img):\n",
        "#     img = img / 2 + 0.5     # unnormalize\n",
        "#     npimg = img.numpy()\n",
        "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "#     plt.axis(False)\n",
        "#     plt.show()\n",
        "\n",
        "# def progress(epoch, loss, epochs=100):\n",
        "#     return HTML(\"\"\"\n",
        "#         <label for=\"file\">Training loss: {loss}</label>\n",
        "#         <progress\n",
        "#             value='{epoch}'\n",
        "#             max='{epochs}',\n",
        "#             style='width: 100%'\n",
        "#         >\n",
        "#             {epoch}\n",
        "#         </progress>\n",
        "#     \"\"\".format(loss=loss, epoch=epoch, epochs=epochs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXcZbnSjPq_2"
      },
      "outputs": [],
      "source": [
        "class BNDeepNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BNDeepNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(3*32*32, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.fc4 = nn.Linear(32, 32)\n",
        "        self.fc5 = nn.Linear(32, 3)\n",
        "        self.bn1 = nn.BatchNorm1d(128)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.bn3 = nn.BatchNorm1d(32)\n",
        "        self.bn4 = nn.BatchNorm1d(32)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc5(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XB9gCLi65txD"
      },
      "outputs": [],
      "source": [
        "data = np.array(df)\n",
        "\n",
        "X_train = torch.tensor(data[:, 1:]).float()/255\n",
        "y_train = torch.tensor(data[:, 0]).long()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laqU5kuxwOnD"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "train_data = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, drop_last=True,\n",
        "                        shuffle=True, num_workers=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DUVNbJiwSfj"
      },
      "outputs": [],
      "source": [
        "def train_test_classification(net, criterion, optimizer,\n",
        "                              train_loader,\n",
        "                              num_epochs=1, verbose=True,\n",
        "                              training_plot=True):\n",
        "  if verbose:\n",
        "    progress_bar = display(progress(0, 0, num_epochs), display_id=True)\n",
        "\n",
        "  net.train()\n",
        "  training_losses = []\n",
        "  for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "      running_loss = 0.0\n",
        "      for i, (inputs,labels) in enumerate(train_loader, 0):\n",
        "          # # get the inputs; data is a list of [inputs, labels]\n",
        "          # inputs, labels = data\n",
        "          # inputs = inputs.to(dev).float()\n",
        "          # labels = labels.to(dev).long()\n",
        "\n",
        "          # zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Make forward pass\n",
        "          outputs = net(inputs)\n",
        "\n",
        "          # Compute Loss\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          # Make backward pass and step optimizer\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # Print statistics\n",
        "          if verbose:\n",
        "            training_losses += [loss.item()]\n",
        "            running_loss += loss.item()\n",
        "            if i % 10 == 9:    # update every 10 mini-batches\n",
        "                progress_bar.update(progress(epoch+1, running_loss / 10, num_epochs))\n",
        "                running_loss = 0.0\n",
        "  \n",
        "  # Evaluate net\n",
        "  net.eval()\n",
        "\n",
        "  # Define training function\n",
        "  def test(data_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for (inputs, labels) in data_loader:\n",
        "        # inputs = inputs.to(dev).float()\n",
        "        # labels = labels.to(dev).long()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    return total, acc\n",
        "\n",
        "\n",
        "  train_total, train_acc = test(train_loader)\n",
        "\n",
        "  if verbose:\n",
        "    print('Accuracy on the %d training samples: %0.2f %%' % (train_total, train_acc))\n",
        "\n",
        "  if training_plot:\n",
        "    plt.plot(training_losses)\n",
        "    plt.xlabel('Batch')\n",
        "    plt.ylabel('Training loss')\n",
        "    plt.show()\n",
        "  \n",
        "  return train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "OJd1-YuAwau6",
        "outputId": "cf4a0eb7-3b32-44c2-bbc0-579f7117f85e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "        <label for=\"file\">Training loss: 0.0005036335554905236</label>\n",
              "        <progress\n",
              "            value='500'\n",
              "            max='500',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            500\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on the 14592 training samples: 99.93 %\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "hidden_layers = [128, 64, 32]\n",
        "batch_size = 128\n",
        "# net = BNDeepNet().to(dev) \n",
        "net = Net('ReLU()', 3*32*32, hidden_layers, 3).to(dev) \n",
        "criterion = nn.MultiMarginLoss(margin=1.0) #nn.CrossEntropyLoss()  \n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
        "train_acc = train_test_classification(net, criterion, optimizer,\n",
        "                                      train_loader,\n",
        "                                      num_epochs=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9Vzhqtr7c6Y",
        "outputId": "b81521ab-fadd-4362-f422-40c2d9809f97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   pixel1  pixel2  pixel3  pixel4  ...  pixel3069  pixel3070  pixel3071  pixel3072\n",
            "0     222     191     140     216  ...        181        161        139         96\n",
            "1     119      76      65      32  ...        115         33         51        167\n",
            "2     157      92     110     181  ...        171        141        128         86\n",
            "3      93     173      78      68  ...        165         71        190        102\n",
            "4     161     213      44     172  ...        207        225        189         70\n",
            "\n",
            "[5 rows x 3072 columns]\n"
          ]
        }
      ],
      "source": [
        "# Predict test set\n",
        "df = pd.read_csv('test.csv')\n",
        "print(df.head())\n",
        "data = np.array(df)\n",
        "X_test = torch.tensor(data).float()/255\n",
        "\n",
        "\n",
        "\n",
        "net.eval()\n",
        "y_pred = net(X_test.to(dev))\n",
        "labels_pred = torch.argmax(y_pred, dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAOeoZH48OuJ"
      },
      "outputs": [],
      "source": [
        "# create the submission file\n",
        "header = ['ImageId', 'Label']\n",
        "with open('submission.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(header)\n",
        "    \n",
        "    for i in range(len(labels_pred)):\n",
        "      writer.writerow([i+1] + [labels_pred[i].item()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEojRbYH9adp",
        "outputId": "4adb2e09-b576-4ffa-b470-4f7f8ad74b2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100% 10.7k/10.7k [00:00<00:00, 61.1kB/s]\n",
            "Successfully submitted to Permuted Animal Faces"
          ]
        }
      ],
      "source": [
        "# submit\n",
        "!kaggle competitions submit permuted-animal-faces -f submission.csv -m \" increase batch to 500 and use Net with hiddne layers  128, 64, 32] and w/multi-margin loss and lr=1e-4\" #\"Result with same model as in the tutorial\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_gDgatsCKJL"
      },
      "source": [
        "Note that you can submit maximum 20 times a day. Participants will need to wait until the next UTC day after submitting the maximum number of daily submissions.\n",
        "\n",
        "And finally you can hand select 2 submissions among your previous ones to be used for the final ranking."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GEV3MSbDQX3"
      },
      "source": [
        "# Part 2. Deep Learning, Deeper Thinking\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vh4iLLj0qN0"
      },
      "source": [
        "## 2.1 Our Data-Processing Wish List\n",
        "\n",
        "By now you should be pretty familiar with classifying animal faces using multi-layer perceptrons. MLPs make very few assumptions about the underlying structure of the data, which make them very flexible in approximating a wide variety of functions. However, sometimes it can be helpful to constrain the set of possible functions we want to approximate by introducing some \"rules\" that these functions need to follow. We call these rules **inductive biases**. \n",
        "\n",
        "For example, one inductive bias might be the rule that \"A cat is a cat, no matter where it is placed in the image. An upper-left-corner cat is just as much of a cat as a lower-right-corner cat.\" That describes an inductive bias called **translational invariance**, which basically says that the class of an object is invariant to translation (it doesn't matter where it is, as long as it's there). If we could have a model that preserves translational invariance, chances are it would be helpful in finding us good models for image processing (more on this later). \n",
        "\n",
        "**Now that you're familiar with the concept of inductive biases, please do the following:**\n",
        "* List one inductive bias other than translational invariance that would be good to have for image processing\n",
        "* Suppose you're trying to develop a model to assign credit scores to people based on their personal data. What kind of inductive biases or data guarantees would you want to impose on this system?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DfgGaluts9P"
      },
      "outputs": [],
      "source": [
        "#Delete the starter text, enter your response, and run the cell.\n",
        "q_2_1 = ''' Rotational invariance would also be a desireable trait of a network.\n",
        "Like the example, a cat is a cat whether no matter if its rotated within the image. \n",
        "\n",
        "First, we might assume that all credit scores belong to some specific distribution. Second,\n",
        "we an introducing bias when we hand select features (personal data in this case) to be used in the model. \n",
        "A good model of credit score should account for all aspects of fiscal behavior, but limit the use\n",
        "of non-financial information. This is potentially problematic if predictors, such as race, gender, religious identity, etc. are applied. \n",
        "For example, race may end up being a strong predictor of credit score. However, this is completely\n",
        "tied to social and economic inequality between racial groups. Thus, while there may be a correlation \n",
        "between this feature and race, the model would likely apply a lower credit score to individual w/o \n",
        "even considering their finances. The model is not a predictor of credit based on fiscal responsibility, but \n",
        "instead on race, gender, or other personal characteristics. \n",
        "\n",
        "On the other hand, if we wanted to equity into the network, we might bias our priors or introduce strong likelihoods\n",
        "that produce a more favorable posterior for disenfranchised groups. While this does not treat everyone equal, we might\n",
        "give certain groups a more positive bias to account for negative credit score impact from racist or sexist features. \n",
        "this type of approach may drive credit scores to be more equal in outcome, and thus, over a long time scale, might \n",
        "result in more loans and greater financial trust of underrepresented groups. \n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxuEtqNmxqkT"
      },
      "source": [
        "## 2.2 The Ethics of Facial Recognition\n",
        "In part 1, we just had you create a network that was good at classifying faces of animals. What happens when this technologies are used on humans? What happens when these technologies are used by law enforcement? In this section, we'll explore these implications. So play your favorite Lo-Fi Beats to Study/Relax To and let's get started!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO8qZ_IDxL8g"
      },
      "source": [
        "### 2.2.1 **America Under Watch**\n",
        "As data scientists, we often complain that we don't have enough data. Sometimes lack of good data isn't the problem. What happens if we collect data *everywhere*? In many countries around the world, facial recognition is used by law enforcement to conduct wide-scale law enforcement. Thankfully that's not the case in the United States. Right? \n",
        "\n",
        "*... Right?* \n",
        "\n",
        "Read the following:\n",
        "\n",
        "* https://www.americaunderwatch.com/\n",
        "\n",
        "**In 200-300 words, please answer the following questions.** \n",
        "* In America Under Watch, the Georgetown Law Center proposes a moratorium (temporary freeze) on the police use of facial recognition. Do you agree or disagree with this choice, and why? \n",
        "* The article mentions the fact that *facial surveillance is disproportionately likely to impact communities of color and communities with lower socio-economic status (SES)*. Think about what this means about what amount + what kinds of data law enforcement collect on people of color. How might this perpetuate cycles of incarceration for people of color in the U.S.?\n",
        "* If facial recognition were to be put in place in a highly secure location, like the White House, what kind of inductive biases would you want to ensure that such a system would have? What guarantees might you want to have about the data that is used to train the network, the data that is collected, and what is done with the data afterward? \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7Bz8XqX26yt"
      },
      "outputs": [],
      "source": [
        "#Delete the starter text, enter your response, and run the cell.\n",
        "q_2_2_1 = '''\n",
        "Your Response to Q 2.2.1 Here (200 - 300 words)\n",
        "\n",
        "- A moratoriam is simply saying that we should not do it right now, but maybe later. The question is if this technology belongs in\n",
        "our society at all or if we are willing to accept it as part of our security measures. While I do not support the use of widespread\n",
        "facial recognition by police in public spaces, I think it is simply inevitable. We should impose a moritorium and then our focus\n",
        "should be on legislation and regulation to ensure that any use of this technology is constitutional and fair. \n",
        "\n",
        "- The prison system is flawed in so many ways, but one of the worst issues is how we reintroduce people into society. We remove \n",
        "people from society and place them in a lonely, isolated, and violent environment for long sentences and then release them and expect\n",
        "them to seamlessly rejoin society. We offer poor or no resources and impose strict probation/parole rules. Even the most minor violations,\n",
        "like being 5 min late to a meeting due to delayed public transportation, can result in one being thrown back in prison. \n",
        "In my opinion, facial recognition and monitoring of those on court supervision would be akin to entrapment. No one member of society commits\n",
        "zero violations of the law. We just are not held accountable for every time we exceed the speed limit, jaywalk, etc. This type of \n",
        "constant monitoring would surely result in a constant cycle of prison-release-prison, especially for individuals already targeted by police, like \n",
        "communities of color. \n",
        "\n",
        "- First off, we would want to ensure that the data are trained on an appropriately diverse data and then no labels are assigned to these individuals\n",
        "that would allow for targeting based on class, religion, etc. A bias we would desire is signficant performance with minimal error. If a level of confidence\n",
        "cannot be achieved, the image should be labeled as unrecognized, not the closest guess. In Jan 2020, a black man was arrested in Detroit based on facial\n",
        "recognition in footage obtained by police. The only resemblance was the fact that both were black. While we do not know the inner workings of the network, \n",
        "many networks have a discrete set of choices and will result in some kind of output. That means that a bias in the system would impose classification scheme \n",
        "in which matches are provided based on probability. This means that the highest probability would be assigned as the match, when this may not be a close match at all,\n",
        "but simply a high enough probability. \n",
        "\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5qeXoWo3Bb6"
      },
      "source": [
        "### 2.2.2 **Grab Some Popcorn**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "wZ8751Th3Vh4",
        "outputId": "a8912404-f558-4724-d692-c00db3a9ba83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video available at https://youtube.com/watch?v=jZjmlJPJgug\n"
          ]
        },
        {
          "data": {
            "image/jpeg": "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",
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"854\"\n",
              "            height=\"480\"\n",
              "            src=\"https://www.youtube.com/embed/jZjmlJPJgug?fs=1\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7fcfe7c19208>"
            ]
          },
          "execution_count": 1,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@markdown That's enough reading for today, don't you think? Grab some popcorn, run this cell, and watch this video\n",
        "from IPython.display import YouTubeVideo\n",
        "video = YouTubeVideo(id=\"jZjmlJPJgug\", width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "\n",
        "video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T79vzE1K4Ho7"
      },
      "source": [
        "**In 200-300 words, please answer the following questions**\n",
        "* In the segment, John Oliver mentions that Clearview AI uses \"publicly available data\", which includes public profile information on Facebook, LinkedIn, Twitter, and Instagram. Clearview argues that this information has all been willingly made public. Do you agree? Why or why not?\n",
        "* Some prominent data scientists claim that \"data/algorithms don't have bias, people have bias\". Do you agree with this sentiment? Why or why not?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqFIndfb4ubV"
      },
      "outputs": [],
      "source": [
        "#Delete the starter text, enter your response, and run the cell.\n",
        "q_2_2_2 = '''\n",
        "- Clearview is clearly acting outside of the law by violating social media terms of service. Just because a car is parked on the street does not mean I can own it if I get in it and start it. Publically accessible does not equal public availabitliy here. Sure, it is \n",
        "almost impossible to stop people from finding our picture on the internet, but using it as data is a violation.\n",
        "\n",
        "- Models are trained to learn based on their structure and the data they are given. Humans choose the model structure, the loss, and then data. I think models become bias because we\n",
        "push them to learn that way. I do not know if I think models are inherently bias w/o human influence. \n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxsQXMFc8v91"
      },
      "source": [
        "# Submit to Airtable\n",
        "**Don't forget to contribute to the conversation in your pod slack channel.** You can do so by copying and pasting some or all of the answers to the above questions, or by commenting and responding to other people's posts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "AlH_Ub579KEJ",
        "outputId": "21927930-ecfd-4921-d985-c0362f88ff18"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://airtable.com/embed/shrzuKoahe4ZQKvND?prefill_pennkey=jabrantl&prefill_pod=superfluous-lyrebird&prefill_q_2_1=+Rotational+invariance+would+also+be+a+desireable+trait+of+a+network.\n",
              "Like+the+example,+a+cat+is+a+cat+whether+no+matter+if+its+rotated+within+the+image.+\n",
              "\n",
              "First,+we+might+assume+that+all+credit+scores+belong+to+some+specific+distribution.+Second,\n",
              "we+an+introducing+bias+when+we+hand+select+features+(personal+data+in+this+case)+to+be+used+in+the+model.+\n",
              "A+good+model+of+credit+score+should+account+for+all+aspects+of+fiscal+behavior,+but+limit+the+use\n",
              "of+non-financial+information.+This+is+potentially+problematic+if+predictors,+such+as+race,+gender,+religious+identity,+etc.+are+applied.+\n",
              "For+example,+race+may+end+up+being+a+strong+predictor+of+credit+score.+However,+this+is+completely\n",
              "tied+to+social+and+economic+inequality+between+racial+groups.+Thus,+while+there+may+be+a+correlation+\n",
              "between+this+feature+and+race,+the+model+would+likely+apply+a+lower+credit+score+to+individual+w/o+\n",
              "even+considering+their+finances.+The+model+is+not+a+predictor+of+credit+based+on+fiscal+responsibility,+but+\n",
              "instead+on+race,+gender,+or+other+personal+characteristics.+\n",
              "\n",
              "On+the+other+hand,+if+we+wanted+to+equity+into+the+network,+we+might+bias+our+priors+or+introduce+strong+likelihoods\n",
              "that+produce+a+more+favorable+posterior+for+disenfranchised+groups.+While+this+does+not+treat+everyone+equal,+we+might\n",
              "give+certain+groups+a+more+positive+bias+to+account+for+negative+credit+score+impact+from+racist+or+sexist+features.+\n",
              "this+type+of+approach+may+drive+credit+scores+to+be+more+equal+in+outcome,+and+thus,+over+a+long+time+scale,+might+\n",
              "result+in+more+loans+and+greater+financial+trust+of+underrepresented+groups.+\n",
              "\n",
              "&prefill_q_2_2_1=\n",
              "Your+Response+to+Q+2.2.1+Here+(200+-+300+words)\n",
              "\n",
              "-+A+moratoriam+is+simply+saying+that+we+should+not+do+it+right+now,+but+maybe+later.+The+question+is+if+this+technology+belongs+in\n",
              "our+society+at+all+or+if+we+are+willing+to+accept+it+as+part+of+our+security+measures.+While+I+do+not+support+the+use+of+widespread\n",
              "facial+recognition+by+police+in+public+spaces,+I+think+it+is+simply+inevitable.+We+should+impose+a+moritorium+and+then+our+focus\n",
              "should+be+on+legislation+and+regulation+to+ensure+that+any+use+of+this+technology+is+constitutional+and+fair.+\n",
              "\n",
              "-+The+prison+system+is+flawed+in+so+many+ways,+but+one+of+the+worst+issues+is+how+we+reintroduce+people+into+society.+We+remove+\n",
              "people+from+society+and+place+them+in+a+lonely,+isolated,+and+violent+environment+for+long+sentences+and+then+release+them+and+expect\n",
              "them+to+seamlessly+rejoin+society.+We+offer+poor+or+no+resources+and+impose+strict+probation/parole+rules.+Even+the+most+minor+violations,\n",
              "like+being+5+min+late+to+a+meeting+due+to+delayed+public+transportation,+can+result+in+one+being+thrown+back+in+prison.+\n",
              "In+my+opinion,+facial+recognition+and+monitoring+of+those+on+court+supervision+would+be+akin+to+entrapment.+No+one+member+of+society+commits\n",
              "zero+violations+of+the+law.+We+just+are+not+held+accountable+for+every+time+we+exceed+the+speed+limit,+jaywalk,+etc.+This+type+of+\n",
              "constant+monitoring+would+surely+result+in+a+constant+cycle+of+prison-release-prison,+especially+for+individuals+already+targeted+by+police,+like+\n",
              "communities+of+color.+\n",
              "\n",
              "-+First+off,+we+would+want+to+ensure+that+the+data+are+trained+on+an+appropriately+diverse+data+and+then+no+labels+are+assigned+to+these+individuals\n",
              "that+would+allow+for+targeting+based+on+class,+religion,+etc.+A+bias+we+would+desire+is+signficant+performance+with+minimal+error.+If+a+level+of+confidence\n",
              "cannot+be+achieved,+the+image+should+be+labeled+as+unrecognized,+not+the+closest+guess.+In+Jan+2020,+a+black+man+was+arrested+in+Detroit+based+on+facial\n",
              "recognition+in+footage+obtained+by+police.+The+only+resemblance+was+the+fact+that+both+were+black.+While+we+do+not+know+the+inner+workings+of+the+network,+\n",
              "many+networks+have+a+discrete+set+of+choices+and+will+result+in+some+kind+of+output.+That+means+that+a+bias+in+the+system+would+impose+classification+scheme+\n",
              "in+which+matches+are+provided+based+on+probability.+This+means+that+the+highest+probability+would+be+assigned+as+the+match,+when+this+may+not+be+a+close+match+at+all,\n",
              "but+simply+a+high+enough+probability.+\n",
              "\n",
              "\n",
              "&prefill_q_2_2_2=\n",
              "-+Clearview+is+clearly+acting+outside+of+the+law+by+violating+social+media+terms+of+service.+Just+because+a+car+is+parked+on+the+street+does+not+mean+I+can+own+it+if+I+get+in+it+and+start+it.+Publically+accessible+does+not+equal+public+availabitliy+here.+Sure,+it+is+\n",
              "almost+impossible+to+stop+people+from+finding+our+picture+on+the+internet,+but+using+it+as+data+is+a+violation.\n",
              "\n",
              "-+Models+are+trained+to+learn+based+on+their+structure+and+the+data+they+are+given.+Humans+choose+the+model+structure,+the+loss,+and+then+data.+I+think+models+become+bias+because+we\n",
              "push+them+to+learn+that+way.+I+do+not+know+if+I+think+models+are+inherently+bias+w/o+human+influence.+\n",
              "\n",
              "&prefill_cumulative_times=[2977.30878067]\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f022cdb7d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from IPython.display import IFrame\n",
        "#@markdown #Run Cell to Show Airtable Form\n",
        "#@markdown ##**Confirm your answers and then click \"Submit\"**\n",
        "\n",
        "def prefill_form(src, fields: dict):\n",
        "  '''\n",
        "  src: the original src url to embed the form\n",
        "  fields: a dictionary of field:value pairs,\n",
        "  e.g. {\"pennkey\": my_pennkey, \"location\": my_location}\n",
        "  '''\n",
        "  prefills = \"&\".join([\"prefill_%s=%s\"%(key, fields[key]) for key in fields])\n",
        "  src = src + prefills\n",
        "  src = \"+\".join(src.split(\" \"))\n",
        "  return src\n",
        "\n",
        "\n",
        "#autofill time if it is not present\n",
        "try: t0;\n",
        "except NameError: t0 = time.time()\n",
        "try: t1;\n",
        "except NameError: t1 = time.time()\n",
        "\n",
        "#autofill fields if they are not present\n",
        "#a missing pennkey and pod will result in an Airtable warning\n",
        "#which is easily fixed user-side.\n",
        "try: my_pennkey;\n",
        "except NameError: my_pennkey = \"\"\n",
        "try: my_pod;\n",
        "except NameError: my_pod = \"Select\"\n",
        "try: q_2_1;\n",
        "except NameError: q_2_1 = \"\"\n",
        "try: q_2_2_1;\n",
        "except NameError: q_2_2_1 = \"\"\n",
        "try: q_2_2_2;\n",
        "except NameError: q_2_2_2 = \"\"\n",
        "\n",
        "\n",
        "times = np.array([t1])-t0\n",
        "\n",
        "fields = {\"pennkey\": my_pennkey,\n",
        "          \"pod\": my_pod,\n",
        "          \"q_2_1\": q_2_1,\n",
        "          \"q_2_2_1\": q_2_2_1,\n",
        "          \"q_2_2_2\": q_2_2_2,\n",
        "          \"cumulative_times\": times}\n",
        "\n",
        "src = \"https://airtable.com/embed/shrzuKoahe4ZQKvND?\"\n",
        "\n",
        "#now instead of the original source url, we do: src = prefill_form(src, fields)\n",
        "display(IFrame(src = prefill_form(src, fields), width = 800, height = 400))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "W3_Homework_JB.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "479f1e5494f4f006e705bc60b75c83849d57e561d86768f65a122aaaf55f6a14"
    },
    "kernelspec": {
      "display_name": "Python 3.9.11 ('pytorch_local')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
