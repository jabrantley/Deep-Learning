{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWOc48yQrvUI"
      },
      "source": [
        "# Implement simple NN model for classification\n",
        "\n",
        "For this notebook, we will just use MNIST for basic analysis. The purpose is to play with a simple network in pytorch for image classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mLNTKY8sEUj",
        "outputId": "d25988bb-ce33-45ac-9b0c-991e75a6743f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(device(type='cpu'), 4)"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# imports\n",
        "import os\n",
        "import csv\n",
        "import json\n",
        "import random\n",
        "import pathlib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dev, torch.get_num_threads()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Get MNIST data\n",
        "Load directly from torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "9913344it [00:00, 10671938.11it/s]                             \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "29696it [00:00, 11963697.20it/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1649664it [00:00, 7692572.81it/s]                             \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5120it [00:00, 16368015.61it/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Define transorms to apply to data\n",
        "transform = [transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))]\n",
        "batch_size_train, batch_size_test = 64, 1000\n",
        "\n",
        "# Get training data\n",
        "train_loader = torch.utils.data.DataLoader(datasets.MNIST('../data/', train=True, download=True,\n",
        "                transform=transforms.Compose(transform)),batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "# Get test data\n",
        "test_loader = torch.utils.data.DataLoader(datasets.MNIST('../data/', train=False, download=True,\n",
        "                             transform=transforms.Compose(transform)),batch_size=batch_size_test, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's define a simple network with just a activation(layer) for layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up simple network with user defined activation function and numbber of layer units\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, actv, num_inputs, hidden_units, num_outputs):\n",
        "        super(Net, self).__init__()\n",
        "        # Get activation function\n",
        "        exec('self.actv = nn.%s'%actv)   \n",
        "        # Define layers\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i in range(len(hidden_units)):\n",
        "          next_num_inputs = hidden_units[i] \n",
        "          self.layers += [nn.Linear(num_inputs, next_num_inputs)]\n",
        "          num_inputs = next_num_inputs\n",
        "\n",
        "        self.out = nn.Linear(num_inputs, num_outputs)\n",
        "        \n",
        "    # Make the forward pass\n",
        "    def forward(self, x):\n",
        "        # Flattening\n",
        "        x = x.view(x.shape[0], -1)  \n",
        "        \n",
        "        # Apply activation function to each layer on the input \n",
        "        for layer in self.layers:\n",
        "          x = self.actv(layer(x))\n",
        "        x = self.out(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's define our train() and test() functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def progress(epoch, loss, epochs=100):\n",
        "    return HTML(\"\"\"\n",
        "        <label for=\"file\">Training loss: {loss}</label>\n",
        "        <progress\n",
        "            value='{epoch}'\n",
        "            max='{epochs}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {epoch}\n",
        "        </progress>\n",
        "    \"\"\".format(loss=loss, epoch=epoch, epochs=epochs))\n",
        "\n",
        "\n",
        "# Define training function\n",
        "def test(data_loader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for (inputs, labels) in data_loader:\n",
        "      outputs = net(inputs)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  acc = 100 * correct / total\n",
        "  return total, acc\n",
        "\n",
        "# NOTE: this training loop only uses the training data for training the params and testing. Its based on a previous notebook where I did not have access to test data during training.\n",
        "# Also this is more about working with pytorch and less about actual results. \n",
        "def train(net, criterion, optimizer,data_loader,num_epochs=1, verbose=True, training_plot=True):\n",
        "  if verbose:\n",
        "    progress_bar = display(progress(0, 0, num_epochs), display_id=True)\n",
        "\n",
        "  # Set to train = true\n",
        "  net.train()\n",
        "  training_losses = []\n",
        "\n",
        "  for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "      running_loss = 0.0\n",
        "      for i, (inputs,labels) in enumerate(data_loader, 0):\n",
        "\n",
        "          # zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Make forward pass\n",
        "          outputs = net(inputs)\n",
        "\n",
        "          # Compute Loss\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          # Make backward pass and step optimizer\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # Print statistics\n",
        "          if verbose:\n",
        "            training_losses += [loss.item()]\n",
        "            running_loss += loss.item()\n",
        "            if i % 10 == 9:    # update every 10 mini-batches\n",
        "                progress_bar.update(progress(epoch+1, running_loss / 10, num_epochs))\n",
        "                running_loss = 0.0\n",
        "  \n",
        "  # Evaluate net\n",
        "  net.eval()\n",
        "\n",
        "  train_total, train_acc = test(train_loader)\n",
        "\n",
        "  if verbose:\n",
        "    print('Accuracy on the %d training samples: %0.2f %%' % (train_total, train_acc))\n",
        "\n",
        "  if training_plot:\n",
        "    plt.plot(training_losses)\n",
        "    plt.xlabel('Batch')\n",
        "    plt.ylabel('Training loss')\n",
        "    plt.show()\n",
        "  \n",
        "  return train_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 1, 28, 28])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "examples = enumerate(train_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "example_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "        <label for=\"file\">Training loss: 0.003547004031133838</label>\n",
              "        <progress\n",
              "            value='310'\n",
              "            max='500',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            310\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "hidden_layers = [32]\n",
        "# net = BNDeepNet().to(dev) \n",
        "net = Net('ReLU()', 1*28*28, hidden_layers, 10).to(dev) \n",
        "criterion = nn.CrossEntropyLoss()  #nn.MultiMarginLoss(margin=1.0) \n",
        "optimizer = optim.SGD(net.parameters(),lr=1e-2)#,momentum=0.5)# optim.Adam(net.parameters(), lr=1e-4)\n",
        "train_acc = train(net, criterion, optimizer,train_loader,num_epochs=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'test' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/justinbrantley/Dropbox/KLAB/Deep-Learning/2_2LayerNN_Classification_Basic.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/justinbrantley/Dropbox/KLAB/Deep-Learning/2_2LayerNN_Classification_Basic.ipynb#ch0000010?line=0'>1</a>\u001b[0m test_acc \u001b[39m=\u001b[39m test(test_loader)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
          ]
        }
      ],
      "source": [
        "test_acc = test(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXcZbnSjPq_2"
      },
      "outputs": [],
      "source": [
        "class BNDeepNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BNDeepNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(3*32*32, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.fc4 = nn.Linear(32, 32)\n",
        "        self.fc5 = nn.Linear(32, 3)\n",
        "        self.bn1 = nn.BatchNorm1d(128)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.bn3 = nn.BatchNorm1d(32)\n",
        "        self.bn4 = nn.BatchNorm1d(32)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc5(x)\n",
        "        return x"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "W3_Homework_JB.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "479f1e5494f4f006e705bc60b75c83849d57e561d86768f65a122aaaf55f6a14"
    },
    "kernelspec": {
      "display_name": "Python 3.9.11 ('pytorch_local')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
